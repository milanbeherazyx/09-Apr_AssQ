{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. What is Bayes' theorem?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bayes' theorem is a fundamental concept in probability theory that describes the relationship between conditional probabilities. It states that the probability of an event A, given that another event B has occurred, can be calculated using the conditional probability of B given A, the marginal probability of A, and the marginal probability of B. In mathematical terms, Bayes' theorem is expressed as:\n",
    "\n",
    ">P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    ">where P(A|B) is the probability of A given B, P(B|A) is the probability of B given A, P(A) is the marginal probability of A, and P(B) is the marginal probability of B. Bayes' theorem is widely used in various fields, including statistics, machine learning, and artificial intelligence, to make predictions and make decisions based on uncertain or incomplete information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bayes' theorem can be expressed mathematically as:\n",
    "\n",
    ">P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    ">where:\n",
    "\n",
    "- P(A|B) is the probability of event A occurring given that event B has occurred (this is called the posterior probability).\n",
    "- P(B|A) is the probability of event B occurring given that event A has occurred (this is called the likelihood).\n",
    "- P(A) is the prior probability of event A occurring (i.e., the probability of A before taking into account any information from event B).\n",
    "- P(B) is the probability of event B occurring (i.e., the total probability of B, which is the sum of the joint probabilities of A and B, and not just the probability of B given A).\n",
    ">Note that Bayes' theorem allows us to update our prior beliefs (represented by P(A)) based on new information (represented by P(B|A))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bayes' theorem is used in practice to update the probability of an event occurring based on new evidence or information. It can be applied in various fields such as statistics, machine learning, medical diagnosis, and natural language processing, among others.\n",
    "\n",
    ">In statistics and machine learning, Bayes' theorem is used to estimate the probability distribution of unknown parameters in a model. It can be used to update prior beliefs about the parameters given new data, resulting in a posterior distribution that reflects the updated beliefs.\n",
    "\n",
    ">In medical diagnosis, Bayes' theorem is used to estimate the probability of a patient having a certain disease given their symptoms and test results. The prior probability is based on the prevalence of the disease in the population, while the likelihood is based on the sensitivity and specificity of the diagnostic tests.\n",
    "\n",
    ">In natural language processing, Bayes' theorem is used in text classification tasks such as spam filtering and sentiment analysis. The probability of a document belonging to a particular class (e.g., spam or not spam) is estimated based on the probability of the words in the document given the class, using the Naive Bayes algorithm.\n",
    "\n",
    ">Overall, Bayes' theorem is a powerful tool for updating beliefs and making decisions based on new evidence, and it has numerous practical applications across a wide range of fields.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bayes' theorem and conditional probability are closely related. Bayes' theorem is a way to calculate conditional probabilities, which is the probability of an event A given that another event B has occurred. Specifically, Bayes' theorem uses the conditional probability of B given A (P(B|A)) and the marginal probability of A (P(A)) to calculate the conditional probability of A given B (P(A|B)).\n",
    "\n",
    ">Bayes' theorem can be written as:\n",
    "\n",
    ">P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    ">where P(A|B) is the conditional probability of A given B, P(B|A) is the conditional probability of B given A, P(A) is the marginal probability of A, and P(B) is the marginal probability of B.\n",
    "\n",
    ">In other words, Bayes' theorem is a way to update our beliefs about the probability of an event A based on new evidence B. It is a powerful tool in statistics and machine learning, and is widely used in a variety of applications such as spam filtering, medical diagnosis, and image recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The choice of which type of Naive Bayes classifier to use depends on the specific problem and the nature of the data. Here are some general guidelines:\n",
    "\n",
    "- If the input features are categorical, use the Multinomial Naive Bayes classifier. This is commonly used for text classification problems, where the input features are the frequencies of different words or phrases.\n",
    "\n",
    "- If the input features are continuous, use the Gaussian Naive Bayes classifier. This is commonly used for problems involving sensor data, such as predicting the quality of a product based on measurements from sensors.\n",
    "\n",
    "- If the input features are a mix of categorical and continuous, or if the categorical features have many possible values, use the Bernoulli Naive Bayes classifier. This is commonly used for problems involving binary data, such as spam detection, where the input features are whether or not certain words or phrases are present in an email.\n",
    "\n",
    ">It's important to keep in mind that these are just general guidelines, and the choice of classifier should ultimately be based on the specific problem and the performance of the classifier on the data. It's always a good idea to try different classifiers and compare their performance using techniques like cross-validation.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Assignment:\n",
    ">You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "\n",
    "\n",
    "| Class | X1=1 | X1=2 | X1=3 | X2=1 | X2=2 | X2=3 | X2=4 |\n",
    "|-------|------|------|------|------|------|------|------|\n",
    "| A     | 3    | 3    | 4    | 4    | 3    | 3    | 3    |\n",
    "| B     | 2    | 2    | 1    | 2    | 2    | 2    | 3    |\n",
    "\n",
    "\n",
    ">Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for X1=3, X2=4 is A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\milan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create the dataset\n",
    "data = {\n",
    "    'Class': ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B'],\n",
    "    'X1': [3, 3, 4, 4, 3, 3, 3, 2, 2, 1, 2, 2, 2, 3],\n",
    "    'X2': [4, 2, 1, 2, 3, 3, 3, 2, 2, 3, 2, 2, 2, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# split dataset into features and target\n",
    "X = df[['X1', 'X2']]\n",
    "y = df['Class']\n",
    "\n",
    "# train the model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X, y)\n",
    "\n",
    "# make predictions on new instance X1=3, X2=4\n",
    "X_new = np.array([[3, 4]])\n",
    "y_pred = gnb.predict(X_new)\n",
    "\n",
    "# print the predicted class\n",
    "print('The predicted class for X1=3, X2=4 is', y_pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
